{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fe9a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.4.3-py3-none-any.whl (985 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.12.0)\n",
      "Installing collected packages: outcome, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed async-generator-1.10 outcome-1.2.0 selenium-4.4.3 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tetiana matviichuk\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1272 sha256=c57370db5c8a1ea2928f711f1652b16e8a6db7f7d2757063ac1aae856f12665f\n",
      "  Stored in directory: c:\\users\\tetiana matviichuk\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement urllib (from versions: none)\n",
      "ERROR: No matching distribution found for urllib\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install bs4\n",
    "!pip install urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4981b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install selenium\n",
    "#!pip install BeautifulSoup4\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e329f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrappercount(date):\n",
    "    url = (\"https://github.com/ehsanulhaq1/russo_ukraine_dataset/tree/main/\"+date)\n",
    "    page = urlopen(url)\n",
    "    html = page.read().decode(\"utf-8\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    \n",
    "    raw_url =\"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/\"\n",
    "    li = []\n",
    "    for i in range(2,20):\n",
    "        ii =\"_\"+f'{i}'+\".csv\"\n",
    "        p = soup.find(\"a\",string=date+ii)\n",
    "        if(p):\n",
    "           li.append(raw_url+date+\"/\"+date+ii)\n",
    "\n",
    "\n",
    "    url = li\n",
    "    df = pd.DataFrame()\n",
    "    for i in url:\n",
    "        fetch = pd.read_csv(i,header = None,delimiter = '\\n')\n",
    "        df = pd.concat([df,fetch], ignore_index=True, sort=False)\n",
    "        #print(date +\" \"+str(len((fetch))))\n",
    "        print(date + \" \"  + str(df.size))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f264e431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m ii \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[0;32m      5\u001b[0m date \u001b[38;5;241m=\u001b[39m idate\u001b[38;5;241m+\u001b[39mii\n\u001b[1;32m----> 6\u001b[0m before \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([before, \u001b[43mscrappercount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mscrappercount\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m url:\n\u001b[1;32m---> 20\u001b[0m     fetch \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df,fetch], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#print(date +\" \"+str(len((fetch))))\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:665\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath_or_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m \u001b[43m_refine_defaults_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelimiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1537\u001b[0m, in \u001b[0;36m_refine_defaults_read\u001b[1;34m(dialect, delimiter, delim_whitespace, engine, sep, error_bad_lines, warn_bad_lines, on_bad_lines, names, prefix, defaults)\u001b[0m\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified a delimiter with both sep and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelim_whitespace=True; you can only specify one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1534\u001b[0m     )\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn as separator or delimiter. This forces the python engine \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich does not accept a line terminator. Hence it is not allowed to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe line terminator as separator.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1541\u001b[0m     )\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;66;03m# assign default separator value\u001b[39;00m\n\u001b[0;32m   1545\u001b[0m     kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m delim_default\n",
      "\u001b[1;31mValueError\u001b[0m: Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator."
     ]
    }
   ],
   "source": [
    "idate = \"2022-02-\"\n",
    "before = pd.DataFrame()\n",
    "for i in range (21,24):\n",
    "    ii = str(i)\n",
    "    date = idate+ii\n",
    "    before = pd.concat([before, scrappercount(date)], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68f045ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m feb_27 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m url_f27:\n\u001b[1;32m----> 9\u001b[0m     fetch \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     feb_27 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([feb_27,fetch], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m feb_27\u001b[38;5;241m.\u001b[39msample()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:665\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath_or_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m \u001b[43m_refine_defaults_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelim_whitespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_bad_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdelimiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1537\u001b[0m, in \u001b[0;36m_refine_defaults_read\u001b[1;34m(dialect, delimiter, delim_whitespace, engine, sep, error_bad_lines, warn_bad_lines, on_bad_lines, names, prefix, defaults)\u001b[0m\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified a delimiter with both sep and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelim_whitespace=True; you can only specify one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1534\u001b[0m     )\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecified \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn as separator or delimiter. This forces the python engine \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich does not accept a line terminator. Hence it is not allowed to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe line terminator as separator.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1541\u001b[0m     )\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delimiter \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;66;03m# assign default separator value\u001b[39;00m\n\u001b[0;32m   1545\u001b[0m     kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m delim_default\n",
      "\u001b[1;31mValueError\u001b[0m: Specified \\n as separator or delimiter. This forces the python engine which does not accept a line terminator. Hence it is not allowed to use the line terminator as separator."
     ]
    }
   ],
   "source": [
    "url_f27 =[ \"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/2022-02-27/2022-02-27_2.csv\",\n",
    "            \"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/2022-02-27/2022-02-27_3.csv\",\n",
    "            \"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/2022-02-27/2022-02-27_4.csv\",\n",
    "            \"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/2022-02-27/2022-02-27_5.csv\",\n",
    "            \"https://raw.githubusercontent.com/ehsanulhaq1/russo_ukraine_dataset/main/2022-02-27/2022-02-27_6.csv\"]\n",
    "\n",
    "feb_27 = pd.DataFrame()\n",
    "for i in url_f27:\n",
    "    fetch = pd.read_csv(i,header = None, delimiter = '\\n')\n",
    "    feb_27 = pd.concat([feb_27,fetch], ignore_index=True, sort=False)\n",
    "feb_27.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cadfc13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-24 41697\n",
      "2022-02-24 83393\n",
      "2022-02-24 125087\n",
      "2022-02-24 166781\n",
      "2022-02-24 208475\n",
      "2022-02-24 250153\n",
      "2022-02-24 291831\n",
      "2022-02-24 333509\n",
      "2022-02-24 375205\n",
      "2022-02-24 416901\n",
      "2022-02-24 458596\n",
      "2022-02-24 500294\n",
      "2022-02-24 541992\n",
      "2022-02-24 583690\n",
      "2022-02-24 625383\n",
      "2022-02-24 667076\n",
      "2022-02-24 708768\n",
      "2022-02-24 750440\n",
      "2022-02-25 41681\n",
      "2022-02-25 83361\n",
      "2022-02-25 125059\n",
      "2022-02-25 166757\n",
      "2022-02-25 208455\n",
      "2022-02-25 250128\n",
      "2022-02-25 291801\n",
      "2022-02-25 333473\n",
      "2022-02-25 375144\n",
      "2022-02-25 416815\n",
      "2022-02-25 458486\n",
      "2022-02-25 500155\n",
      "2022-02-25 541823\n",
      "2022-02-25 583491\n",
      "2022-02-25 625175\n",
      "2022-02-25 666859\n",
      "2022-02-25 708543\n",
      "2022-02-25 750227\n",
      "2022-02-26 33335\n",
      "2022-02-26 66670\n",
      "2022-02-26 100029\n",
      "2022-02-26 133388\n",
      "2022-02-26 166747\n",
      "2022-02-26 200107\n",
      "2022-02-26 233467\n",
      "2022-02-26 266826\n",
      "2022-02-26 300174\n",
      "2022-02-26 333522\n",
      "2022-02-26 366870\n",
      "2022-02-26 400220\n",
      "2022-02-26 433570\n",
      "2022-02-26 466919\n",
      "2022-02-26 500268\n",
      "2022-02-26 533617\n",
      "2022-02-26 566966\n",
      "2022-02-26 600323\n",
      "2022-02-27 49999\n",
      "2022-02-27 99998\n",
      "2022-02-27 149997\n",
      "2022-02-27 199996\n",
      "2022-02-27 211952\n",
      "2022-02-27 245317\n",
      "2022-02-27 278681\n",
      "2022-02-27 312045\n",
      "2022-02-27 345394\n",
      "2022-02-27 378743\n",
      "2022-02-27 412091\n",
      "2022-02-27 445430\n",
      "2022-02-27 478769\n",
      "2022-02-27 512107\n",
      "2022-02-27 545471\n",
      "2022-02-27 578835\n",
      "2022-02-27 612199\n",
      "2022-02-27 645552\n",
      "2022-02-28 49999\n",
      "2022-02-28 99998\n",
      "2022-02-28 149997\n",
      "2022-02-28 199996\n",
      "2022-02-28 249995\n",
      "2022-02-28 258693\n",
      "2022-02-28 292046\n",
      "2022-02-28 325399\n",
      "2022-02-28 358751\n",
      "2022-02-28 392113\n",
      "2022-02-28 425475\n",
      "2022-02-28 458836\n",
      "2022-02-28 492172\n",
      "2022-02-28 525508\n",
      "2022-02-28 558843\n",
      "2022-02-28 592194\n",
      "2022-02-28 625545\n",
      "2022-02-28 658895\n",
      "2022-03-01 33875\n",
      "2022-03-01 40422\n",
      "2022-03-01 90421\n",
      "2022-03-01 140420\n",
      "2022-03-01 190419\n",
      "2022-03-01 200885\n",
      "2022-03-02 49999\n",
      "2022-03-02 99998\n",
      "2022-03-02 149997\n",
      "2022-03-02 184383\n",
      "2022-03-03 31440\n",
      "2022-03-03 81439\n",
      "2022-03-03 131438\n",
      "2022-03-03 181437\n",
      "2022-03-03 204062\n",
      "2022-03-04 11245\n",
      "2022-03-04 61244\n",
      "2022-03-04 111243\n",
      "2022-03-04 161242\n",
      "2022-03-04 192800\n",
      "2022-03-05 49999\n",
      "2022-03-05 99998\n",
      "2022-03-05 149997\n",
      "2022-03-05 199424\n",
      "2022-03-06 49999\n",
      "2022-03-06 99998\n",
      "2022-03-06 149997\n",
      "2022-03-06 199996\n",
      "2022-03-06 217653\n",
      "2022-03-07 49999\n",
      "2022-03-07 99998\n",
      "2022-03-07 149997\n",
      "2022-03-07 186788\n",
      "2022-03-08 49999\n",
      "2022-03-08 99998\n",
      "2022-03-08 149997\n",
      "2022-03-08 199996\n",
      "2022-03-08 208581\n",
      "2022-03-09 49999\n",
      "2022-03-09 99998\n",
      "2022-03-09 149997\n",
      "2022-03-09 181888\n",
      "2022-03-10 49999\n",
      "2022-03-10 99998\n",
      "2022-03-10 149997\n",
      "2022-03-10 199996\n",
      "2022-03-10 200378\n",
      "2022-03-11 8263\n",
      "2022-03-11 58262\n",
      "2022-03-11 108261\n",
      "2022-03-11 158260\n",
      "2022-03-11 175252\n",
      "2022-03-12 26803\n",
      "2022-03-12 76802\n",
      "2022-03-12 126801\n",
      "2022-03-12 176800\n",
      "2022-03-12 187880\n",
      "2022-03-13 49999\n",
      "2022-03-13 99998\n",
      "2022-03-13 149997\n",
      "2022-03-13 182514\n",
      "2022-03-14 49999\n",
      "2022-03-14 99998\n",
      "2022-03-14 149997\n",
      "2022-03-14 199996\n",
      "2022-03-14 201325\n",
      "2022-03-15 49999\n",
      "2022-03-15 99998\n",
      "2022-03-15 149997\n",
      "2022-03-15 170958\n",
      "2022-03-16 35980\n",
      "2022-03-16 85979\n",
      "2022-03-16 135978\n",
      "2022-03-16 185977\n",
      "2022-03-16 191221\n",
      "2022-03-17 49999\n",
      "2022-03-17 99998\n",
      "2022-03-17 149997\n",
      "2022-03-17 180209\n",
      "2022-03-18 49999\n",
      "2022-03-18 99998\n",
      "2022-03-18 149997\n",
      "2022-03-18 198851\n",
      "2022-03-19 49999\n",
      "2022-03-19 99998\n",
      "2022-03-19 149997\n",
      "2022-03-19 199996\n",
      "2022-03-19 215491\n",
      "2022-03-20 49999\n",
      "2022-03-20 99998\n",
      "2022-03-20 149997\n",
      "2022-03-20 182598\n",
      "2022-03-21 49999\n",
      "2022-03-21 99998\n",
      "2022-03-21 149997\n",
      "2022-03-21 199996\n",
      "2022-03-21 202259\n",
      "2022-03-22 49999\n",
      "2022-03-22 99998\n",
      "2022-03-22 149997\n",
      "2022-03-22 173545\n",
      "2022-03-23 49999\n",
      "2022-03-23 99998\n",
      "2022-03-23 149997\n",
      "2022-03-23 197834\n",
      "2022-03-24 49999\n",
      "2022-03-24 99998\n",
      "2022-03-24 149997\n",
      "2022-03-24 199996\n",
      "2022-03-24 213257\n",
      "2022-03-25 49999\n",
      "2022-03-25 99998\n",
      "2022-03-25 149997\n",
      "2022-03-25 187721\n",
      "2022-03-26 49999\n",
      "2022-03-26 99998\n",
      "2022-03-26 149997\n",
      "2022-03-26 199996\n",
      "2022-03-26 208995\n",
      "2022-03-27 49999\n",
      "2022-03-27 99998\n",
      "2022-03-27 149997\n",
      "2022-03-27 178258\n",
      "2022-03-28 49999\n",
      "2022-03-28 99998\n",
      "2022-03-28 106752\n",
      "2022-03-28 156751\n",
      "2022-03-28 195590\n",
      "2022-03-29 49999\n",
      "2022-03-29 99998\n",
      "2022-03-29 149997\n",
      "2022-03-29 199996\n",
      "2022-03-29 213978\n",
      "2022-03-30 49999\n",
      "2022-03-30 99998\n",
      "2022-03-30 149997\n",
      "2022-03-30 180827\n",
      "2022-03-31 49999\n",
      "2022-03-31 99998\n",
      "2022-03-31 149997\n",
      "2022-03-31 199996\n",
      "2022-03-31 206009\n",
      "2022-04-01 49999\n",
      "2022-04-01 99998\n",
      "2022-04-01 149997\n",
      "2022-04-01 180008\n",
      "2022-04-02 49999\n",
      "2022-04-02 99998\n",
      "2022-04-02 149997\n",
      "2022-04-02 198996\n",
      "2022-04-03 49999\n",
      "2022-04-03 99998\n",
      "2022-04-03 149997\n",
      "2022-04-03 199996\n",
      "2022-04-03 214502\n",
      "2022-04-04 49999\n",
      "2022-04-04 99998\n",
      "2022-04-04 149997\n",
      "2022-04-04 186330\n",
      "2022-04-05 49999\n",
      "2022-04-05 99998\n",
      "2022-04-05 149997\n",
      "2022-04-05 199996\n",
      "2022-04-05 209779\n",
      "2022-04-06 49999\n",
      "2022-04-06 99998\n",
      "2022-04-06 149997\n",
      "2022-04-06 178884\n",
      "2022-04-07 49999\n",
      "2022-04-07 99998\n",
      "2022-04-07 149997\n",
      "2022-04-07 199996\n",
      "2022-04-07 203240\n",
      "2022-04-08 49999\n",
      "2022-04-08 99998\n",
      "2022-04-08 149997\n",
      "2022-04-08 178997\n",
      "2022-04-09 49999\n",
      "2022-04-09 99998\n",
      "2022-04-09 149997\n",
      "2022-04-09 193721\n",
      "2022-04-10 49999\n",
      "2022-04-10 99998\n",
      "2022-04-10 149997\n",
      "2022-04-10 199996\n",
      "2022-04-10 215938\n",
      "2022-04-11 49999\n",
      "2022-04-11 99998\n",
      "2022-04-11 149997\n",
      "2022-04-11 186351\n",
      "2022-04-12 49999\n",
      "2022-04-12 99998\n",
      "2022-04-12 149997\n",
      "2022-04-12 199996\n",
      "2022-04-12 208459\n",
      "2022-04-13 49999\n",
      "2022-04-13 99998\n",
      "2022-04-13 149997\n",
      "2022-04-13 183715\n",
      "2022-04-14 49999\n",
      "2022-04-14 99998\n",
      "2022-04-14 149997\n",
      "2022-04-14 199996\n",
      "2022-04-14 205779\n",
      "2022-04-15 49999\n",
      "2022-04-15 99998\n",
      "2022-04-15 149997\n",
      "2022-04-15 180739\n",
      "2022-04-16 49999\n",
      "2022-04-16 99998\n",
      "2022-04-16 149997\n",
      "2022-04-16 199996\n",
      "2022-04-16 200499\n",
      "2022-04-17 49999\n",
      "2022-04-17 99998\n",
      "2022-04-17 149997\n",
      "2022-04-17 175291\n",
      "2022-04-18 49999\n",
      "2022-04-18 99998\n",
      "2022-04-18 149997\n",
      "2022-04-18 192757\n",
      "2022-04-19 49999\n",
      "2022-04-19 99998\n",
      "2022-04-19 149997\n",
      "2022-04-19 199996\n",
      "2022-04-19 216810\n",
      "2022-04-20 49999\n",
      "2022-04-20 99998\n",
      "2022-04-20 149997\n",
      "2022-04-20 194144\n",
      "2022-04-21 49999\n",
      "2022-04-21 99998\n",
      "2022-04-21 149997\n",
      "2022-04-21 199996\n",
      "2022-04-21 213207\n",
      "2022-04-22 49999\n",
      "2022-04-22 99998\n",
      "2022-04-22 149997\n",
      "2022-04-22 184909\n",
      "2022-04-23 49999\n",
      "2022-04-23 99998\n",
      "2022-04-23 149997\n",
      "2022-04-23 199996\n",
      "2022-04-23 208029\n",
      "2022-04-24 49999\n",
      "2022-04-24 99998\n",
      "2022-04-24 149997\n",
      "2022-04-24 177352\n",
      "2022-04-25 49999\n",
      "2022-04-25 99998\n",
      "2022-04-25 149997\n",
      "2022-04-25 199996\n",
      "2022-04-25 201670\n",
      "2022-04-26 49999\n",
      "2022-04-26 99998\n",
      "2022-04-26 149997\n",
      "2022-04-26 179552\n",
      "2022-04-27 49999\n",
      "2022-04-27 99998\n",
      "2022-04-27 149997\n",
      "2022-04-27 199996\n",
      "2022-04-27 203671\n",
      "2022-04-28 49999\n",
      "2022-04-28 99998\n",
      "2022-04-28 149997\n",
      "2022-04-28 175016\n",
      "2022-04-29 49999\n",
      "2022-04-29 99998\n",
      "2022-04-29 149997\n",
      "2022-04-29 199994\n",
      "2022-04-30 49999\n",
      "2022-04-30 99998\n",
      "2022-04-30 149997\n",
      "2022-04-30 199996\n",
      "2022-04-30 220984\n",
      "2022-05-01 49999\n",
      "2022-05-01 99998\n",
      "2022-05-01 149997\n",
      "2022-05-01 193378\n",
      "2022-05-02 49999\n",
      "2022-05-02 99998\n",
      "2022-05-02 149997\n",
      "2022-05-02 199996\n",
      "2022-05-02 214323\n",
      "2022-05-03 49999\n",
      "2022-05-03 99998\n",
      "2022-05-03 149997\n",
      "2022-05-03 183992\n",
      "2022-05-04 49999\n",
      "2022-05-04 99998\n",
      "2022-05-04 149997\n",
      "2022-05-04 199996\n",
      "2022-05-04 212280\n",
      "2022-05-05 49999\n",
      "2022-05-05 99998\n",
      "2022-05-05 149997\n",
      "2022-05-05 181538\n",
      "2022-05-06 49999\n",
      "2022-05-06 99998\n",
      "2022-05-06 149997\n",
      "2022-05-06 199996\n",
      "2022-05-06 214697\n",
      "2022-05-07 49999\n",
      "2022-05-07 99998\n",
      "2022-05-07 149997\n",
      "2022-05-07 182801\n",
      "2022-05-08 49999\n",
      "2022-05-08 99998\n",
      "2022-05-08 149997\n",
      "2022-05-08 199996\n",
      "2022-05-08 200570\n",
      "2022-05-09 49999\n",
      "2022-05-09 99998\n",
      "2022-05-09 149997\n",
      "2022-05-09 179770\n",
      "2022-05-10 49999\n",
      "2022-05-10 99998\n",
      "2022-05-10 149997\n",
      "2022-05-10 199996\n",
      "2022-05-10 203797\n",
      "2022-05-11 49999\n",
      "2022-05-11 99998\n",
      "2022-05-11 149997\n",
      "2022-05-11 162381\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         ii \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)\n\u001b[0;32m     35\u001b[0m     date \u001b[38;5;241m=\u001b[39m idate\u001b[38;5;241m+\u001b[39mii\n\u001b[1;32m---> 36\u001b[0m     may \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([may, \u001b[43mscrappercount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m june \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     40\u001b[0m idate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022-06-\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36mscrappercount\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrappercount\u001b[39m(date):\n\u001b[0;32m      2\u001b[0m     url \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/ehsanulhaq1/russo_ukraine_dataset/tree/main/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdate)\n\u001b[1;32m----> 3\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     html \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "feb_start = pd.DataFrame()\n",
    "idate = \"2022-02-\"\n",
    "for i in range (24,29):\n",
    "    ii = str(i)\n",
    "    date = idate+ii\n",
    "    feb_start = pd.concat([feb_start, scrappercount(date)], ignore_index=True, sort=False)\n",
    "\n",
    "march = pd.DataFrame()\n",
    "idate = \"2022-03-\"\n",
    "for i in range (1,32):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    march = pd.concat([march, scrappercount(date)], ignore_index=True, sort=False)\n",
    "\n",
    "april = pd.DataFrame()\n",
    "idate = \"2022-04-\"\n",
    "for i in range (1,31):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    april = pd.concat([april, scrappercount(date)], ignore_index=True, sort=False)\n",
    "\n",
    "may = pd.DataFrame()\n",
    "idate = \"2022-05-\"\n",
    "for i in range (1,32):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    may = pd.concat([may, scrappercount(date)], ignore_index=True, sort=False)\n",
    "\n",
    "    \n",
    "june = pd.DataFrame()\n",
    "idate = \"2022-06-\"\n",
    "for i in range (1,31):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    june = pd.concat([june, scrappercount(date)], ignore_index=True, sort=False)\n",
    "\n",
    "july = pd.DataFrame()\n",
    "idate = \"2022-07-\"\n",
    "for i in range (1,32):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    july = pd.concat([july, scrappercount(date)], ignore_index=True, sort=False)\n",
    "    \n",
    "august = pd.DataFrame()\n",
    "idate = \"2022-08-\"\n",
    "for i in range (1,26):\n",
    "    if i<10:\n",
    "        ii =\"0\"+str(i)\n",
    "    else:\n",
    "        ii = str(i)\n",
    "    date = idate+ii\n",
    "    august = pd.concat([august, scrappercount(date)], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d13ce1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'august' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maugust\u001b[49m\u001b[38;5;241m.\u001b[39msample\n",
      "\u001b[1;31mNameError\u001b[0m: name 'august' is not defined"
     ]
    }
   ],
   "source": [
    "august.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2019f",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca390e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "\n",
    "tweets.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many unique language\n",
    "# tweets are present in the dataset\n",
    "print(tweets[\"lang\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6690ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# before removing the non-english tweets\n",
    "print(tweets.shape)\n",
    " \n",
    "# removing all the tweets expect the\n",
    "# non-english tweets\n",
    "tweets = tweets[tweets['lang'] == 'en']\n",
    "print(\"After removing non-english Tweets\")\n",
    " \n",
    "# only the number of english tweets\n",
    "print(tweets.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing RT, Punctuation etc\n",
    "def remove_rt(x): return re.sub('RT @\\w+: ', \" \", x)\n",
    " \n",
    "def rt(x): return re.sub(\n",
    "    \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", x)\n",
    " \n",
    "tweets[\"content\"] = tweets.content.map(remove_rt).map(rt)\n",
    "tweets[\"content\"] = tweets.content.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c3dd4",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebe492",
   "metadata": {},
   "source": [
    "### Tweet volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b45e0",
   "metadata": {},
   "source": [
    "### Date + keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd83420",
   "metadata": {},
   "source": [
    "### Hashtags + mention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da5964",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53ea0d",
   "metadata": {},
   "source": [
    "The sentiment analysis procedure includes collecting the data, analyzing it, pre-processing it, and then sentiment identification, feature selection, sentiment classification, and removing the polarity and subjectivity of it. TextBlob library is used to analyze the sentiment of the tweets. A tweet with a negative score is greater than a positive score, marked as positive if the opposite then as negative else neutral. The number of tweets for each unique day in the sample dataset is removed, and then the number of tweets with positive, negative, and neutral tweets on that day is calculated to find out their percentages. It helps us to understand the reaction of people on a day-to-day basis. Below is the code snippet for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2161c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[['polarity', 'subjectivity']] = tweets['content'].apply(\n",
    "    lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    " \n",
    "for index, row in tweets['content'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "     \n",
    "    if neg > pos:\n",
    "        tweets.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif pos > neg:\n",
    "        tweets.loc[index, 'sentiment'] = \"positive\"\n",
    "    else:\n",
    "        tweets.loc[index, 'sentiment'] = \"neutral\"\n",
    "         \n",
    "    tweets.loc[index, 'neg'] = neg\n",
    "    tweets.loc[index, 'neu'] = neu\n",
    "    tweets.loc[index, 'pos'] = pos\n",
    "    tweets.loc[index, 'compound'] = comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the results of the above operation, then we can use the following code snippet.\n",
    "tweets[[\"content\", \"sentiment\", \"polarity\",\n",
    "        \"subjectivity\", \"neg\", \"neu\", \"pos\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb489475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to calculate the total percentage of Positive, Negative, and Neutral tweets we will use the following code snippet. \n",
    "\n",
    "total_pos = len(tweets.loc[tweets['sentiment'] == \"positive\"])\n",
    "total_neg = len(tweets.loc[tweets['sentiment'] == \"negative\"])\n",
    "total_neu = len(tweets.loc[tweets['sentiment'] == \"neutral\"])\n",
    "total_tweets = len(tweets)\n",
    "print(\"Total Positive Tweets % : {:.2f}\"\n",
    "      .format((total_pos/total_tweets)*100))\n",
    "print(\"Total Negative Tweets % : {:.2f}\"\n",
    "      .format((total_neg/total_tweets)*100))\n",
    "print(\"Total Neutral Tweets % : {:.2f}\"\n",
    "      .format((total_neu/total_tweets)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display this result using a Pie Chart, then we can do that with the help of the below code snippet\n",
    "mylabels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "mycolors = [\"Green\", \"Red\", \"Blue\"]\n",
    " \n",
    "plt.figure(figsize=(8, 5),\n",
    "           dpi=600)  # Push new figure on stack\n",
    "myexplode = [0, 0.2, 0]\n",
    "plt.pie([total_pos, total_neg, total_neu], colors=mycolors,\n",
    "        labels=mylabels, explode=myexplode)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff74838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  to see the sentiments over 65 days, then we can do that with the help of the below code snippet.\n",
    "\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "neu_list = []\n",
    "for i in tweets[\"date\"].unique():\n",
    "    temp = tweets[tweets[\"date\"] == i]\n",
    "    positive_temp = temp[temp[\"sentiment\"] == \"positive\"]\n",
    "    negative_temp = temp[temp[\"sentiment\"] == \"negative\"]\n",
    "    neutral_temp = temp[temp[\"sentiment\"] == \"neutral\"]\n",
    "    pos_list.append(((positive_temp.shape[0]/temp.shape[0])*100, i))\n",
    "    neg_list.append(((negative_temp.shape[0]/temp.shape[0])*100, i))\n",
    "    neu_list.append(((neutral_temp.shape[0]/temp.shape[0])*100, i))\n",
    " \n",
    "neu_list = sorted(neu_list, key=lambda x: x[1])\n",
    "pos_list = sorted(pos_list, key=lambda x: x[1])\n",
    "neg_list = sorted(neg_list, key=lambda x: x[1])\n",
    " \n",
    "x_cord_neg = []\n",
    "y_cord_neg = []\n",
    " \n",
    "x_cord_pos = []\n",
    "y_cord_pos = []\n",
    " \n",
    "x_cord_neu = []\n",
    "y_cord_neu = []\n",
    " \n",
    "for i in neg_list:\n",
    "    x_cord_neg.append(i[0])\n",
    "    y_cord_neg.append(i[1])\n",
    " \n",
    " \n",
    "for i in pos_list:\n",
    "    x_cord_pos.append(i[0])\n",
    "    y_cord_pos.append(i[1])\n",
    " \n",
    "for i in neu_list:\n",
    "    x_cord_neu.append(i[0])\n",
    "    y_cord_neu.append(i[1])\n",
    " \n",
    " \n",
    "plt.figure(figsize=(16, 9),\n",
    "           dpi=600)  # Push new figure on stack\n",
    "plt.plot(y_cord_neg, x_cord_neg, label=\"negative\",\n",
    "         color=\"red\")\n",
    "plt.plot(y_cord_pos, x_cord_pos, label=\"positive\",\n",
    "         color=\"green\")\n",
    "plt.plot(y_cord_neu, x_cord_neu, label=\"neutral\",\n",
    "         color=\"blue\")\n",
    "plt.xticks(np.arange(0, len(tweets[\"date\"].unique()) + 1, 5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='x')\n",
    " \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd6ab8a",
   "metadata": {},
   "source": [
    "### Word Popularity using N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad25b2c",
   "metadata": {},
   "source": [
    "We have used the feature extraction module of Scikit-Learn to find out the most popular words and a group of adjacent words. Here we get a Bag of Word model after tokenizing, removing the stop words, and stemming on previously cleaned texts. Below is the code snippet for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82618cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuation\n",
    "def remove_punct(text):\n",
    "\ttext = \"\".join([char for char in text if\n",
    "\t\t\t\t\tchar not in string.punctuation])\n",
    "\ttext = re.sub('[0-9]+', '', text)\n",
    "\treturn text\n",
    "\n",
    "\n",
    "tw_list['punct'] = tw_list['content'].apply(\n",
    "lambda x: remove_punct(x))\n",
    "\n",
    "# Applying tokenization\n",
    "def tokenization(text):\n",
    "\ttext = re.split('\\W+', text)\n",
    "\treturn text\n",
    "\n",
    "\n",
    "tw_list['tokenized'] = tw_list['punct'].apply(\n",
    "\tlambda x: tokenization(x.lower()))\n",
    "\n",
    "# Removing stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "\ttext = [word for word in text if\n",
    "\t\t\tword not in stopword]\n",
    "\treturn text\n",
    "\n",
    "tw_list['nonstop'] = tw_list['tokenized'].apply(\n",
    "lambda x: remove_stopwords(x))\n",
    "\n",
    "# Applying Stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "\ttext = [ps.stem(word) for word in text]\n",
    "\treturn text\n",
    "\n",
    "tw_list['stemmed'] = tw_list['nonstop'].apply(\n",
    "lambda x: stemming(x))\n",
    "\n",
    "tw_list.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade188bf",
   "metadata": {},
   "source": [
    "To find out the most used words from it we need a Bag of Word first. Bag of Word is a matrix where each row represents a specific text, and each column represents a word in the vocabulary. Then a vector with the sum of each word occurrence in all texts is generated. In other words, the elements for each column of the Bag of Words matrix are added. At last, the list with the word and their occurrence count is sorted. Below is the code snippet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9626a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Countvectorizer\n",
    "countVectorizer = CountVectorizer(analyzer=clean_text)\n",
    "countVector = countVectorizer.fit_transform(tw_list['content'])\n",
    "count_vect_df = pd.DataFrame(\n",
    "\tcountVector.toarray(),\n",
    "columns=countVectorizer.get_feature_names())\n",
    "count_vect_df.head()\n",
    "\n",
    "# Most Used Words\n",
    "count = pd.DataFrame(count_vect_df.sum())\n",
    "countdf = count.sort_values(0,\n",
    "\t\t\t\t\t\t\tascending=False).head(20)\n",
    "countdf[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find out the group of adjacent words we will take the help of Unigram and Bigram. Below is the code snippet for the same:\n",
    "\n",
    "# Function to ngram\n",
    "def get_top_n_gram(corpus, ngram_range, n=None):\n",
    "\tvec = CountVectorizer(ngram_range=ngram_range,\n",
    "\t\t\t\t\t\tstop_words='english').fit(corpus)\n",
    "\tbag_of_words = vec.transform(corpus)\n",
    "\tsum_words = bag_of_words.sum(axis=0)\n",
    "\twords_freq = [(word, sum_words[0, idx])\n",
    "\t\t\t\tfor word, idx in vec.vocabulary_.items()]\n",
    "\twords_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "\treturn words_freq[:n]\n",
    "\n",
    "# n2_bigram\n",
    "n2_bigrams = get_top_n_gram(tw_list['content'], (2, 2), 20)\n",
    "plt.figure(figsize=(8, 5),\n",
    "\t\tdpi=600) # Push new figure on stack\n",
    "\n",
    "sns_plot = sns.barplot(x=1, y=0, data=pd.DataFrame(n2_bigrams))\n",
    "plt.savefig('bigram.jpg') # Save that figure\n",
    "\n",
    "# n3_trigram\n",
    "n3_trigrams = get_top_n_gram(tw_list['content'], (3, 3), 20)\n",
    "\n",
    "plt.figure(figsize=(8, 5),\n",
    "\t\tdpi=600) # Push new figure on stack\n",
    "\n",
    "sns_plot = sns.barplot(x=1, y=0, data=pd.DataFrame(n3_trigrams))\n",
    "plt.savefig('trigram.jpg') # Save that figure\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
